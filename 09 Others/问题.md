# LLMs 面试题 - 问题文档

## [大模型（LLMs）基础面](https://articles.zsxq.com/id_mw52p1pfbzql.html)

1. 1 目前 主流的开源模型体系 有哪些？
2. 2 prefix Decoder 和 causal Decoder 和 Encoder-Decoder 区别是什么？
3. 3 大模型LLM的 训练目标 是什么？
4. 4 涌现能力是啥原因？
5. 5 为何现在的大模型大部分是Decoder only结构？
6. 6 简单 介绍一下 大模型【LLMs】？
7. 7 大模型【LLMs】后面跟的 175B、60B、540B等 指什么？
8. 8 大模型【LLMs】具有什么优点？
9. 9 大模型【LLMs】具有什么缺点？
10. 10 encoder-only, decoder-only, encoder-decoder的区别?
11. 11 BART、llama、gpt、t5、palm等主流模型异同点?
12. 12 prefix LM 和 causal LM 区别是什么?

## [Layer normalization 篇](https://articles.zsxq.com/id_pzcgd4ovk098.html)

13. 1 LN 在 LLMs 中的不同位置 有什么区别么？如果有，能介绍一下区别么？

## [LLMs 激活函数篇](https://articles.zsxq.com/id_6xm3wzzice2s.html)

14. 1 介绍一下 FFN 块 计算公式？
15. 2 介绍一下 GeLU 计算公式？
16. 3 介绍一下 Swish 计算公式？
17. 4 介绍一下 使用 GLU 线性门控单元的 FFN 块 计算公式？
18. 5 介绍一下 使用 GeLU 的 GLU 块 计算公式？
19. 6 介绍一下 使用 Swish 的 GLU 块 计算公式？
20. 7 各LLMs 都使用哪种激活函数？
21. 8 Adam优化器和SGD的区别？

## [Attention 升级面](https://articles.zsxq.com/id_u67us9zex93d.html)

22. 1 传统 Attention 存在哪些问题？
23. 2 Attention 有哪些 优化方向？
24. 3 Attention 变体有哪些？
25. 4 Multi-Query Attention 篇
26. 4.1 Multi-head Attention 存在什么问题？
27. 4.2 介绍一下 Multi-Query Attention？
28. 4.3 对比一下 Multi-head Attention 和 Multi-Query Attention？
29. 4.4 Multi-Query Attention 这样做的好处是什么？
30. 4.5 有 哪些模型 是 使用 Multi-Query Attention？
31. 5 Grouped-query Attention
32. 5.1 什么是 Grouped-query Attention？
33. 5.2 有哪些大模型使用 Grouped-query Attention？
34. 6 FlashAttention
35. 6.1 为什么需要  FlashAttention？
36. 6.2 简单介绍一下 FlashAttention？
37. 6.3 简单介绍一下 FlashAttention 核心？
38. 6.4 介绍一下 FlashAttention 优点？
39. 6.5 介绍一下 FlashAttention 代表模型？
40. 7 并行 transformer block
41. 8 attention计算复杂度以及如何改进？
42. 9 Paged Attention篇
43. 9.1 简单介绍一下 Paged Attention？
44. 1、MHA，GQA，MQA 三种注意力机制是否了解?区别是什么?
45. 3.1 Cross Attention 和 Self Attention 都是基于注意力机制的，有什么相同点？
46. 3.2 Cross Attention 和 Self Attention 都是基于注意力机制的，有什么不同点？
47. 4.2 Cross Attention 和 多头注意力（Multi-Head Attention） 都是基于注意力机制的，有什么异同点？

## [transformers 操作篇](https://articles.zsxq.com/id_rsll7gsd8va5.html)

48. 1. 如何 利用 transformers 加载 Bert 模型？
49. 2. 如何 利用 transformers 输出 Bert 指定 hidden\_state？
50. 3. BERT 获取最后一层或每一层网络的向量输出

## [二、大模型（LLMs）进阶面](https://articles.zsxq.com/id_xr65bxpcsnoh.html)

51. 3.1 什么是 LLMs 复读机问题？
52. 3.2 为什么会出现 LLMs 复读机问题？
53. 3.3 如何缓解 LLMs 复读机问题？
54. 4.1 llama 输入句子长度理论上可以无限长吗？

## [大模型（LLMs）微调面](https://articles.zsxq.com/id_kv7jdah2zw5n.html)

55. 39 大模型 sft 过程中，为什么会出现第二个epoch的时候loss会突然下降问题？
56. 1 如果想要在某个模型基础上做全参数微调，究竟需要多少显存？
57. 2 为什么SFT之后感觉LLM傻了?
58. 3 SFT 指令微调数据 如何构建?
59. 3.1 提升sft的prompt的代表性有什么好的方法？
60. 3.2 提升sft的prompt的数据量有什么好的方法？
61. 4 领域模型Continue PreTrain 数据选取？
62. 5 领域数据训练后，通用能力往往会有所下降，如何缓解模型遗忘通用能力？
63. 6 领域模型Continue PreTrain ，如何 让模型在预训练过程中就学习到更多的知识？
64. 7 进行SFT操作的时候，基座模型选用Chat还是Base?
65. 8 领域模型微调 指令\&数据输入格式 要求？
66. 9 领域模型微调 领域评测集 构建？
67. 10 领域模型词表扩增是不是有必要的？
68. 11 如何训练自己的大模型？
69. 12 训练中文大模型有啥经验？
70. 13 指令微调的好处？
71. 14 预训练和微调哪个阶段注入知识的？
72. 15 想让模型学习某个领域或行业的知识，是应该预训练还是应该微调？

## [大模型（LLMs）langchain 面](https://articles.zsxq.com/id_ve2dgaiqrjzv.html)

73. 一、什么是 LangChain?
74. 2.1 LangChain 中 Components and Chains 是什么？
75. 2.2 LangChain 中 Prompt Templates and Values 是什么？
76. 2.3 LangChain 中 Example Selectors 是什么？
77. 2.4 LangChain 中 Output Parsers 是什么？
78. 2.5 LangChain 中 Indexes and Retrievers 是什么？
79. 2.6 LangChain 中  Chat Message History 是什么？
80. 2.7 LangChain 中  Agents and Toolkits 是什么？

## [多轮对话中让AI保持长期记忆的8种优化方式篇](https://articles.zsxq.com/id_3qgicwcwzjpi.html)

81. 2.1 获取全量历史对话
82. 2.2 滑动窗口获取最近部分对话内容

## [基于LLM+向量库的文档对话 经验面](https://articles.zsxq.com/id_xk58m8ok2sob.html)

83. 1.1 为什么 大模型 需要 外挂(向量)知识库？
84. 1.2. 基于LLM+向量库的文档对话 思路是怎么样？
85. 1.3. 基于LLM+向量库的文档对话 核心技术是什么？
86. 1.4. 基于LLM+向量库的文档对话 prompt 模板 如何构建？

## [RAG（Retrieval-Augmented Generation）面](https://articles.zsxq.com/id_xk58m8ok2sob.html)

87. 一、LLMs 已经具备了较强能力了，存在哪些不足点?
88. 二、什么是 RAG?
89. 2.1 R：检索器模块
90. 2.1.1 如何获得准确的语义表示？
91. 2.1.2 如何协调查询和文档的语义空间？
92. 2.1.3 如何对齐检索模型的输出和大语言模型的偏好？
93. 2.2 G：生成器模块
94. 2.2.1 生成器介绍
95. 2.2.2 如何通过后检索处理提升检索结果？
96. 2.2.3 如何优化生成器应对输入数据？
97. 三、使用 RAG 的好处?

## [大模型（LLMs）RAG 版面分析——表格识别方法篇](https://articles.zsxq.com/id_7x4qv94hxv8r.html)

98. 3.1 传统方法
99. 3.2 pdfplumber表格抽取
100. 3.2.1 pdfplumber 如何进行 表格抽取？
101. 3.2.2 pdfplumber 常见的表格抽取模式？

## [大模型（LLMs）RAG 版面分析——文本分块面](https://articles.zsxq.com/id_iw7debl8akxh.html)

102. 2.1 一般的文本分块方法
103. 2.2 正则拆分的文本分块方法
104. 2.3 Spacy Text Splitter 方法
105. 2.4 基于 langchain 的 CharacterTextSplitter 方法

## [大模型外挂知识库优化——如何利用大模型辅助召回？](https://articles.zsxq.com/id_oznm6qixjw61.html)

106. 策略一： HYDE
107. 1. 介绍一下 HYDE 思路？
108. 2. 介绍一下 HYDE 问题？
109. 策略二： FLARE
110. 1. 为什么 需要 FLARE ？
111. 2. FLARE 有哪些召回策略？

## [大模型外挂知识库优化——负样本样本挖掘篇](https://articles.zsxq.com/id_wa7nl8wsuilh.html)

112. 2.1 随机采样策略（Random Sampling）方法
113. 2.2 Top-K负例采样策略（Top-K Hard Negative Sampling）方法

## [检索增强生成(RAG) 优化策略篇](https://articles.zsxq.com/id_gu4p7gszsh82.html)

114. 1.1 RAG 工作流程
115. 3.1 如何利用 知识图谱（KG）进行上下文增强？
116. 3.1.1 典型RAG架构中，向量数据库进行上下文增强 存在哪些问题？
117. 3.1.2 如何利用 知识图谱（KG）进行上下文增强？

## [RAG 关键痛点及对应解决方案](https://articles.zsxq.com/id_1bmbedojsj0t.html)

118. 问题一：内容缺失问题
119. 1.1 介绍一下 内容缺失问题？
120. 1.2 如何 解决 内容缺失问题？
121. 问题二：错过排名靠前的文档
122. 2.1 介绍一下 错过排名靠前的文档 问题？
123. 2.2 如何 解决 错过排名靠前的文档 问题？
124. 问题三：脱离上下文 — 整合策略的限制
125. 3.1 介绍一下 脱离上下文 — 整合策略的限制 问题？
126. 3.2 如何 解决 脱离上下文 — 整合策略的限制 问题？
127. 问题四：未能提取答案
128. 4.1 介绍一下 未能提取答案 问题？
129. 4.2 如何 解决 未能提取答案 问题？

## [大模型（LLMs）参数高效微调(PEFT) 面](https://articles.zsxq.com/id_ipkod91a939n.html)

130. 1. 微调方法是啥？如何微调？
131. 2. 为什么需要 PEFT？
132. 3. 介绍一下 PEFT？
133. 4. PEFT 有什么优点？

## [提示学习（Prompting）](https://articles.zsxq.com/id_662wpbw47gtj.html)

134. 4.1 前缀微调（Prefix-tining）篇
135. 4.1.1 为什么需要 前缀微调（Prefix-tining）？
136. 4.1.2 前缀微调（Prefix-tining）思路是什么？
137. 4.1.3 前缀微调（Prefix-tining）的优点是什么？
138. 4.1.4 前缀微调（Prefix-tining）的缺点是什么？

## [LoRA 系列篇](https://articles.zsxq.com/id_gjkhd8xn4pvt.html)

139. 1.1 什么是 LoRA？
140. 1.2 LoRA 的思路是什么？
141. 1.3 LoRA 的特点是什么？
142. 1.4 简单描述一下 LoRA?
143. 1.5 解释一下 LORA 微调的原理和计算流程？
144. 2.1 QLoRA篇
145. 2.1.1 QLoRA 的思路是怎么样的？
146. 2.1.2 QLoRA 的特点是什么？
147. 2.1.3 QLORA相比LORA做了哪些改进?
148. 2.2 AdaLoRA篇
149. 2.3 LongLoRA篇
150. 2.3.1 为什么需要 LongLoRA？
151. 2.3.2 LongLoRA 思路是什么？
152. 2.3.3 介绍一下 shift short attention？

## [如何使用 PEFT库 中 LoRA？](https://articles.zsxq.com/id_8lx1t1t3w4qf.html)

153. 3.1 模型加载 策略有哪些？
154. 3.2 模型显存占用的部分有哪些？
155. 3.3 模型显存占用 优化策略？
156. 3.3.1 8bit量化 优化策略？
157. 3.3.2 梯度检查 优化策略？
158. 3.4 如何 向 模型 加入PEFT策略？

## [大模型 SFT 方式对比篇](https://articles.zsxq.com/id_e2piver2uzei.html)

159. 3.1 介绍一下 Full Fine Tuning？
160. 3.2 介绍一下 Full Fine Tuning 优点？
161. 3.3 介绍一下 Full Fine Tuning 缺点？
162. 4.1 介绍一下 Parameter-Efficient Fine-Tuning？
163. 5.1 介绍一下 LoRA？
164. 5.2 介绍一下 LoRA 流程？
165. 5.3 介绍一下 LoRA 优点？
166. 5.4 介绍一下 LoRA 缺点？
167. 6.1 介绍一下 QLoRA？
168. 6.2 介绍一下 QLoRA 流程？

## [大模型（LLMs）推理面](https://articles.zsxq.com/id_b9eecaoga75i.html)

169. 1. 为什么大模型推理时显存涨的那么多还一直占着？
170. 2. 大模型在gpu和cpu上推理速度如何？
171. 3. 推理速度上，int8和fp16比起来怎么样？
172. 4. 大模型有推理能力吗？

## [大模型（LLMs）增量预训练篇](https://articles.zsxq.com/id_jfq8la7g20ww.html)

173. 1. 为什么要增量预训练？
174. 2. 进行 增量预训练 需要做哪些准备工作？
175. 3. 增量预训练 所用 训练框架？
176. 4. 增量预训练 训练流程 是怎么样？

## [增量预训练（Pretrain）样本拼接篇](https://articles.zsxq.com/id_8f35p8piwl4v.html)

177. 1.1 Prefill（输入理解与初始化）阶段
178. 1.2 Decoding（递归推理与解码输出）阶段
179. 2.1 Throughput（吞吐量）
180. 2.2 First Token Latency（首字延迟）
181. 2.3 Latency（延迟）
182. 2.4 QPS（每秒请求数）

## [增量预训练（Pretrain）样本拼接篇](https://articles.zsxq.com/id_enteq22h1nhq.html)

183. 2.1 拼接方式一：Random Concatenate
184. 2.2 拼接方式二：Random Concatenate + NoiseMask
185. 2.3 拼接方式三：Random Concatenate + Cluster
186. 2.4 拼接方式四：IN-CONTEXT PRETRAINING

## [基于lora的llama2二次预训练](https://articles.zsxq.com/id_xo09u14omdjw.html)

187. 一、为什么需要 对 llama2 做 基于lora的二次预训练?

## [九、大模型（LLMs）评测面](https://articles.zsxq.com/id_j9wcj62eovgc.html)

188. 1 大模型怎么评测？
189. 2 大模型的honest原则是如何实现的？模型如何判断回答的知识是训练过的已知的知识，怎么训练这种能力？
190. 3 如何衡量大模型水平？
191. 4 大模型评估方法 有哪些？

## [大模型（LLMs）强化学习面](https://articles.zsxq.com/id_20xnfnoprj9s.html)

192. 1 简单介绍强化学习？
193. 2 简单介绍一下 RLHF？
194. 3 奖励模型需要和基础模型一致吗？
195. 4 RLHF 在实践过程中存在哪些不足？
196. 5 如何解决 人工产生的偏好数据集成本较高，很难量产问题？
197. 6 如何解决三个阶段的训练（SFT-\>RM-\>PPO）过程较长，更新迭代较慢问题？
198. 7 如何解决 PPO 的训练过程同时存在4个模型（2训练，2推理），对计算资源的要求较高 问题？
199. 8 强化学习跟大语言模型的本质联系是什么？

## [大模型（LLMs）强化学习——RLHF及其变种面](https://articles.zsxq.com/id_3ct6sw0wouna.html)

200. 2.1 具体介绍一下 预训练（Pre-training）？
201. 3.1 具体介绍一下 有监督微调（Supervised Tinetuning）？
202. 3.2 有监督微调（Supervised Tinetuning）的训练数据格式是什么样？
203. 3.3 预训练（Pre-training） vs 有监督微调（Supervised Tinetuning）区别？
204. 4.1 简单介绍一下 对齐（Alignment）？

## [大模型（LLMs）强化学习—— PPO 面](https://articles.zsxq.com/id_s8kwqw1gowvh.html)

205. 3.1 什么是 PPO 中 采样过程？
206. 3.2 介绍一下 PPO 中 采样策略？
207. 3.3 PPO 中 采样策略中，如何评估“收益”？

## [RLHF平替算法DPO篇](https://articles.zsxq.com/id_mlq44r1p7nob.html)

208. 三、DPO 微调流程 ?

## [reward 篇](https://articles.zsxq.com/id_vblb0j5qnaxg.html)

209. 1 介绍一下 RM模型？
210. 2 为什么需要 RM模型？
211. 3 RM模型训练数据如何构建？
212. 4 reward 模型训练步骤中，为什么这一步骤在标注数据过程中不让人直接打分，而是去标排列序列呢?
213. 5 reward 模型的 loss 是怎么计算的?

## [强化学习在自然语言处理下的应用篇](https://articles.zsxq.com/id_5tsn84l32eea.html)

214. 1.1 介绍一下强化学习？
215. 1.2 介绍一下强化学习 的 状态（States） 和 观测（Observations）？
216. 1.3 强化学习 有哪些 动作空间（Action Spaces），他们之间的区别是什么？

## [大模型（LLMs）显存问题面](https://articles.zsxq.com/id_jhiocx89p3su.html)

217. 大模型大概有多大，模型文件有多大?

## [大模型（LLMs）分布式训练面](https://articles.zsxq.com/id_ah2ibj3z22c7.html)

218. 1 理论篇
219. 1.1 训练 大语言模型 存在问题？
220. 1.2 什么是 点对点通信？
221. 1.3 什么是 集体通信？
222. 1.4 什么是 数据并行？
223. 1.5 数据并行 如何 提升效率？
224. 1.6 什么是 流水线并行？
225. 1.7 什么是 张量并行 (intra-layer)？
226. 1.8 数据并行 vs 张量并行 vs 流水线并行?
227. 1.9 什么是 3D并行？
228. 1.10 想要训练1个LLM，如果只想用1张显卡，那么对显卡的要求是什么？
229. 1.11 如果有N张显存足够大的显卡，怎么加速训练？
230. 1.12 如果显卡的显存不够装下一个完整的模型呢？
231. 1.13 PP推理时，是一个串行的过程，1个GPU计算，其他空闲，有没有其他方式？
232. 1.14 3种并行方式可以叠加吗？
233. 1.15 Colossal-AI 有1D/2D/2.5D/3D，是什么情况？
234. 1.16 除了3D并行有没有其他方式大规模训练？
235. 1.17 有了ZeRO系列，为什么还需要3D并行？
236. 1.18 平民适不适合玩3D并行？
237. 1.19 平民适不适合直接上多机多卡的ZeRO3（万兆网）？
238. 1.20 分布式并行及显存优化技术并行技术有哪一些，都有什么特点？
239. 1.21 显存优化技术有哪一些，都有什么特点？
240. 1.22 常见的分布式训练框架哪一些，都有什么特点？
241. 2 实践篇
242. 2.1 假如有超多的8卡A100节点（DGX A100），如何应用3D并行策略？
243. 2.2 如果想构这样一个大规模并行训练系统，训练框架如何选？
244. 2.3 训练框架如何选？

## [图解分布式训练（六） —— Pytorch的 DeepSpeed 详细解析](https://articles.zsxq.com/id_kmq9rn2vo4kz.html)

245. 2.1 DeepSpeed 介绍
246. 2.2 DeepSpeed 基础的概念
247. 2.3 DeepSpeed 支持的功能
248. 4.1 DeepSpeed 安装
249. 4.2 DeepSpeed 使用

## [图解分布式训练（七）—— accelerate 分布式训练 详细解析](https://articles.zsxq.com/id_o5wkeionnqr7.html)

250. 二、什么是 accelerate 分布式训练?

## [图解分布式训练（九）—— Megatron-LM 篇](https://articles.zsxq.com/id_o4qtcspmuwqv.html)

251. 1、Activation Recomputation是怎么实现的?
252. 2、Megatron中的OverlappedDistributed Optimizer 是如何实现的?
253. 3、Megatron-LM 中 Context Parallel 篇
254. 3.1 介绍一下 Megatron-LM 中 Context Parallel 实现原理？

## [分布式训练 Trick 汇总篇](https://articles.zsxq.com/id_fu9065izm2m4.html)

255. 1.1 数据并行 FSDP
256. 1.2 数据并行 DDP
257. 1.3 数据并行 ZeRO
258. 1.3.1 Model state
259. 1.3.2 Residual state
260. 1.3.3 offload

## [大模型（LLMs）agent 面](https://articles.zsxq.com/id_le02luntesap.html)

261. 2.1 介绍一下 规划（planning）？
262. 2.1.1 拆解子目标和任务分解
263. 2.1.1.1 如何进行 拆解子目标和任务分解？
264. 2.1.1.2 拆解子目标和任务分解 有哪些方法？
265. 2.1.2 模型自我反省
266. 2.1.2.1 如何进行 模型自我反省？
267. 2.1.2.2 模型自我反省 有哪些方法？
268. 2.2 介绍一下 记忆（Memory）？
269. 2.3 介绍一下 工具使用（tool use）？

## [十五、LLMs 位置编码篇](https://articles.zsxq.com/id_amt4qkusdcir.html)

270. 3.1 训练式位置编码篇
271. 5.1 旋转位置编码 RoPE 思路是什么？
272. 6.1 什么是 长度外推问题？
273. 6.2 长度外推问题 的 解决方法 有哪些？
274. 7.1 ALiBi (Attention with Linear Biases) 思路是什么？

## [LLMs Tokenizer 篇](https://articles.zsxq.com/id_6z8ptdwqeid7.html)

275. 1 介绍一下 Byte-Pair Encoding(BPE) ？
276. 2 Byte-Pair Encoding(BPE) 如何构建词典？
277. 3 Byte-Pair Encoding(BPE) 具有什么优点？
278. 4 Byte-Pair Encoding(BPE) 具有什么缺点？
279. 5 手撕 Byte-Pair Encoding(BPE) ？
280. 1 介绍一下 Byte-level BPE ？
281. 2 Byte-level BPE 如何构建词典？
282. 3 Byte-level BPE 具有什么优点？
283. 4 Byte-level BPE 具有什么缺点？

## [大模型（LLMs）推理加速篇](https://articles.zsxq.com/id_kgzsxgro8cee.html)

284. 1.1 Prefill（输入理解与初始化）阶段
285. 1.2 Decoding（递归推理与解码输出）阶段
286. 2.1 Throughput（吞吐量）
287. 2.2 First Token Latency（首字延迟）
288. 2.3 Latency（延迟）
289. 2.4 QPS（每秒请求数）

## [大模型（LLMs）加速篇](https://articles.zsxq.com/id_w9wewc152eux.html)

290. 1 当前优化模型最主要技术手段有哪些？
291. 2 推理加速框架有哪一些？都有什么特点？
292. 3 vLLM 篇
293. 3.1 vLLM 的 功能有哪些？

## [大模型推理加速工具 —— vLLM](https://articles.zsxq.com/id_zw5h9ogvac2w.html)

294. 1.1 前言
295. 1.2 为什么 需要 vLLM ?
296. 1.3 vLLM 具有哪些特点 ?
297. 1.4 vLLM 支持哪些 Huggingface 模型 ?

## [纯Python超轻量高性能LLM推理框架 —— LightLLM](https://articles.zsxq.com/id_9a643feq2b0b.html)

298. 1.1 前言
299. 1.2 为什么 需要 LightLLM ?
300. 1.3 目前 LLM推理框架 有 哪些?
301. 2.1 什么是 LightLLM ？
302. 2.2 Token Attention 介绍？
303. 2.3 Efficient Router 介绍？

## [LLM推理技术之StreamingLLM：如何拥有无限长生成能力](https://articles.zsxq.com/id_w1gwi9z7qm5s.html)

304. 1.1 大型语言模型（LLM）存在什么问题？
305. 1.2 StreamingLLM 背景介绍
306. 1.3 StreamingLLM 核心问题？

## [SwiftInfer —— 大模型无限流式输入推理飙升46%，打破多轮对话长度限制](https://articles.zsxq.com/id_0rpua5fejfwc.html)

307. SwiftInfer 篇：基于TensorRT的StreamingLLM实现

## [LLMs 对比篇](https://articles.zsxq.com/id_fsq8czgwjxse.html)

308. 3.1 llama 系列篇
309. 3.1.1 llama 篇
310. 3.1.1.1 llama 训练数据 介绍
311. 3.1.1.2 llama 模型参数量 介绍
312. 3.1.1.3 llama 模型结构 介绍
313. 3.1.1.4 llama 训练目标 介绍
314. 3.1.1.5 llama tokenizer 介绍
315. 3.1.1.6 llama 衍生模型 介绍
316. 3.1.1.7 llama 词表扩展: Chinese LLaMA
317. 3.2.1 llama2 篇
318. 3.2.1 llama2 系列 数据预处理方式？
319. 3.2.2 llama2 系列 Tokenizer 处理方式？
320. 3.2.3 llama2 系列 Architectural？
321. 3.2.4 llama2 系列 content长度？
322. 3.2 Mistral 7B 系列篇
323. 3.2.1  Mistral 7B Architectural？
324. 3.3 Qwen 系列篇
325. 3.3.1 Qwen 系列 数据预处理方式？
326. 3.3.2 Qwen 系列 Tokenizer 处理方式？
327. 3.3.3 Qwen 系列 ARCHITECTURE？
328. 3.4 Baichuan 系列篇
329. 3.4.1 Baichuan2 篇
330. 3.4.1.1 Baichuan2 系列 数据预处理方式？
331. 3.4.1.2 Baichuan2 系列 Tokenizer 处理方式？
332. 3.4.1.2 Baichuan2 系列 Architecture ？
333. 3.5 GLM 系列篇
334. 3.5.1 ChatGLM-6B 篇
335. 3.5.1.1 ChatGLM-6B 结构特点？
336. 3.5.1.2 ChatGLM-6B 训练目标？
337. 3.5.1.3 ChatGLM-6B  tokenizer？
338. 3.6 BLOOM 系列篇
339. 3.6.1 BLOOM 篇
340. 3.6.1.1 BLOOM 训练数据构建？
341. 3.6.1.2 BLOOM 模型参数量？
342. 3.6.1.3 BLOOM 模型结构？
343. 3.6.1.4 BLOOM 训练目标？
344. 3.6.1.5 BLOOM tokenizer?
345. 4.1 大模型训练共同点？
346. 4.2 大模型训练不同点？
347. 5.1 LLaMA、ChatGLM 和 BLOOM 对比
348. 5.2 LLaMA、ChatGLM 和 BLOOM 的 tokenizer 比较
349. 5.3LLaMA、ChatGLM 和 BLOOM 的 结果 比较

## [LLMs 对比篇](https://articles.zsxq.com/id_0j7k3gxa5hpm.html)

350. 1、prefix-tuning的prefix tokens是双向注意力吗？
351. 2、chatglm1和chatglm2的attention mask是怎么样的？
352. 3、llama的attention mask是怎么样的？

## [百川智能baichuan7B、13B、53B、baichuan2 总结篇](https://articles.zsxq.com/id_ma6pw7v2g9pi.html)

353. 1. 你了解baichuan-7B解构么？介绍一下？
354. 2. baichuan-7B 如何 收集原始数据并 构建 训练数据？
355. 3. baichuan-7B 如何 提高 训练稳定性和吞吐？

## [思维链 Chain-of-Thought（COT）篇](https://articles.zsxq.com/id_c0jpjo7q95wg.html)

356. 三、思维链提示 与 标准的提示学习方法有什么不同?
357. 四、思维链提示 为什么可以提高语言模型的复杂推理能力?它的优势在哪里?

## [思维链 Chain-of-Thought（COT）变体篇](https://articles.zsxq.com/id_thdljw9vgxt1.html)

358. 思维链 Chain-of-Thought（COT）：思维链的启蒙
359. 1. 什么是 思维链 Chain-of-Thought（COT）？
360. 2. 思维链 Chain-of-Thought（COT）是思路是什么？
361. 3. 思维链 Chain-of-Thought（COT）存在问题？
362. 思维树 Tree of Thoughts（TOT）：一种用树结构解决复杂问题的方法
363. 1. 为什么需要 思维树 Tree of Thoughts（TOT）？
364. 2. 什么是 思维树 Tree of Thoughts（TOT）？
365. 3. 思维树 Tree of Thoughts（TOT）涉及问题有哪些？

## 22.1 [MOE（Mixture-of-Experts）篇](https://articles.zsxq.com/id_5anfhj9qoh2v.html)

366. 3.1 MOE + 数据并行?
367. 3.2 MOE + 模型并行?

## [自定义 CUDA 函数的轻量级包装器 —— bitsandbytes篇](https://articles.zsxq.com/id_2nwi4napgvlh.html)

368. 一、什么是 bitsandbytes?

## [命名实体识别常见面试篇](https://articles.zsxq.com/id_2nueuvwwm7v0.html)

369. 1.1 什么是CRF？CRF的主要思想是什么？
370. 1.2 CRF的三个基本问题是什么？
371. 1.3 线性链条件随机场的参数化形式？
372. 1.4 CRF的优缺点是什么？
373. 1.5 HMM与CRF的区别？
374. 1.6 生成模型与判别模型的区别？

## [向量检索常见面试篇](https://articles.zsxq.com/id_dnq0o4aicjso.html)

375. 1.1 Annoy
376. 1.1.1 Annoy 介绍
377. 1.1.2 Annoy 使用
378. 1.2 Faiss

## [大模型推理加速——KV Cache篇](https://articles.zsxq.com/id_swmfcls3sp1j.html)

379. 2.1 不使用 KV Cache 场景
380. 2.2 使用 KV Cache 场景

## [千面郎君 篇（三十一章）—— OpenAI o1 篇](https://articles.zsxq.com/id_71rmw7acx3cd.html)

381. 1.1 Shortcut learning (捷径学习)
382. 1.1.1 什么是 Shortcut learning (捷径学习)？
383. 1.1.2 Shortcut learning (捷径学习) 包含哪些关键特征？
384. 1.1.3 Shortcut learning (捷径学习) 优点是什么？
385. 1.1.4 Shortcut learning (捷径学习) 缺点是什么？
386. 1.2 Journey learning (旅程学习)
387. 1.2.1 什么是 Journey learning (旅程学习)？
388. 1.2.2 Journey learning (旅程学习) 包含哪些关键特征？
389. 1.2.3 Journey learning (旅程学习) 优点是什么？
390. 1.3 Shortcut learning (捷径学习) vs Journey learning (旅程学习)
391. 2.1 o1 的长思维链是什么样子？
392. 2.2 长思维 (Long thought) 是如何工作的？
393. 2.3 如何构建长思维？

## [OpenAI o1 面试篇](https://articles.zsxq.com/id_032nwgcgwhc6.html)

394. Q: o1 的训练方法与之前的模型有何主要区别？
395. Q: o1 的"思考"过程与简单的提示有何不同？
396. Q: 为什么 o1 在推理任务上比之前的模型更强大？
397. Q: o1 如何处理安全性问题？

## [Scaling LLM Test-Time：谁说类o1推理一定要用RL?](https://articles.zsxq.com/id_71l9woqohebk.html)

398. Scaling LLM Test-Time：谁说类o1推理一定要用RL?
399. 1.1 为什么需要 Scaling LLM Test-Time？
400. 1.2 三种 Scaling LLM Test-Time 类型定义？
401. 1.3 有哪些 Scaling Test-Time的方法？
402. 二、方法一：纯 Inference Scaling 篇
403. 2.1 Inferece Test-Time的统一视角：Proposer \& Verifier
404. 2.2 Proposer \& Verifier 实例：Best-of-N
