| Title| Year |Paper|
| ------- | ----- | ------ |
|[YUAN 2.0: A Large Language Model with Localized Filtering-based Attention](https://arxiv.org/ftp/arxiv/papers/2311/2311.15786.pdf)|2023| [[Paper]]( https://arxiv.org/ftp/arxiv/papers/2311/2311.15786.pdf) ,[[Code]](https://github.com/IEIT-Yuan/Yuan-2.0) ,[[Note]](https://mp.weixin.qq.com/s/JOpgdsKgn913Y55leVs3mg)|
|[Fast Inference of Mixture-of-Experts Language Models with Offloading](https://arxiv.org/pdf/2312.17238.pdf)|Arxiv2023|[[Paper]](https://arxiv.org/pdf/2312.17238.pdf) ,[[Code]](https://huggingface.co/blog/zh/mixtral)|

