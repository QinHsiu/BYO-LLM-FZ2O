| Name| Description |Resources|
| ------- | ----- | ------ |
|llama.cpp|Port of Facebook's LLaMA model in C/C++|[[Code]](https://github.com/ggerganov/llama.cpp)|
|llama2.c|Inference Llama 2 in one file of pure C|[[Code]](https://github.com/karpathy/llama2.c)|
|vllm|A high-throughput and memory-efficient inference and serving engine for LLMs|[[Code]](https://github.com/vllm-project/vllm)|
|ollama|Ollama 是一个功能强大且易于使用的LLM工具|[Code](https://github.com/ollama/ollama) [UI](https://github.com/open-webui/open-webui)|
|SGLang|一个用于大型语言模型和视觉语言模型的推理框架|[Code](https://github.com/sgl-project/sglang) [使用说明](https://mp.weixin.qq.com/s/tyG6hDIf3XmWvw6t6SPOFA)|
|TensorRT-LLM|NVIDIA高性能LLM推理框架|[[Code]](https://github.com/NVIDIA/TensorRT-LLM)|
|LMDeploy|LLM部署工具包|[[Code]](https://github.com/InternLM/lmdeploy)|
|TGI|Text Generation Inference|[[Code]](https://github.com/huggingface/text-generation-inference)|
|llama.cpp|C++实现的LLM推理|[[Code]](https://github.com/ggerganov/llama.cpp)|
